{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1273/1273 [15:38<00:00,  1.36it/s]\n",
      "100%|██████████| 319/319 [04:19<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ YOLO dataset for CBIS-DDSM (Mass Detection) created successfully!\n",
      "Ultralytics 8.3.107  Python-3.11.9 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=E:\\PFE\\Flower code\\yolo models\\yolo11m.pt, data=E:\\PFE\\Flower code\\data created\\client_cbis_ddsm_1\\cbis_ddsm.yaml, epochs=100, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=4, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train11\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 23        [16, 19, 22]  1   1411795  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \n",
      "YOLO11m summary: 231 layers, 20,053,779 parameters, 20,053,763 gradients, 68.2 GFLOPs\n",
      "\n",
      "Transferred 643/649 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed . AMP training on NVIDIA GeForce GTX 1660 SUPER GPU may cause NaN losses or zero-mAP results, so AMP will be disabled during training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\PFE\\Flower code\\data created\\client_cbis_ddsm_1\\train\\labels... 1273 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1273/1273 [08:25<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: E:\\PFE\\Flower code\\data created\\client_cbis_ddsm_1\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\PFE\\Flower code\\data created\\client_cbis_ddsm_1\\valid\\labels... 319 images, 0 backgrounds, 0 corrupt: 100%|██████████| 319/319 [02:12<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: E:\\PFE\\Flower code\\data created\\client_cbis_ddsm_1\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train11\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0001, momentum=0.937) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train11\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      7.96G      2.646      3.643        1.9         18        640:  11%|█         | 17/160 [13:02<7:26:00, 187.14s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "# ✅ Define dataset paths\n",
    "DATASET_ROOT = \"E:\\PFE\\Flower code\\data created\\client_cbis_ddsm_1\"\n",
    "TRAIN_PATH = \"E:\\PFE\\Flower code\\data original\\DATA\\Mass\\Train\"\n",
    "TEST_PATH = \"E:\\PFE\\Flower code\\data original\\DATA\\Mass\\Test\"\n",
    "\n",
    "# ✅ Create YOLO dataset structure\n",
    "train_img_dir = os.path.join(DATASET_ROOT, \"train/images\")\n",
    "train_lbl_dir = os.path.join(DATASET_ROOT, \"train/labels\")\n",
    "valid_img_dir = os.path.join(DATASET_ROOT, \"valid/images\")\n",
    "valid_lbl_dir = os.path.join(DATASET_ROOT, \"valid/labels\")\n",
    "os.makedirs(train_img_dir, exist_ok=True)\n",
    "os.makedirs(train_lbl_dir, exist_ok=True)\n",
    "os.makedirs(valid_img_dir, exist_ok=True)\n",
    "os.makedirs(valid_lbl_dir, exist_ok=True)\n",
    "\n",
    "# ✅ Function to Extract Bounding Boxes from Masks\n",
    "def find_bounding_boxes(mask_path):\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    binary_mask = np.uint8(binary_mask)\n",
    "    \n",
    "    # ✅ Apply Morphological Operations to Remove Noise\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    cleaned_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    contours, _ = cv2.findContours(cleaned_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    boxes = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if w > 10 and h > 10:\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "    return boxes\n",
    "\n",
    "# ✅ Collect Image Data (Unified Mass Detection)\n",
    "def collect_data(root_path):\n",
    "    data = []\n",
    "    for class_label in [\"BENIGN\", \"MALIGNANT\"]:\n",
    "        class_path = os.path.join(root_path, class_label)\n",
    "        all_files = sorted(os.listdir(class_path))\n",
    "        for i in range(0, len(all_files), 2):\n",
    "            img_file = all_files[i]\n",
    "            mask_file = all_files[i + 1] if i + 1 < len(all_files) else None\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            mask_path = os.path.join(class_path, mask_file) if mask_file and \"MASK\" in mask_file else None\n",
    "            if mask_path and os.path.exists(mask_path):\n",
    "                boxes = find_bounding_boxes(mask_path)\n",
    "                data.append([img_path, boxes, 0])  # ✅ Single class for all masses\n",
    "    return pd.DataFrame(data, columns=[\"image\", \"boxes\", \"label\"])\n",
    "\n",
    "# ✅ Load and Merge Data\n",
    "train_df = collect_data(TRAIN_PATH)\n",
    "test_df = collect_data(TEST_PATH)\n",
    "merged_df = pd.concat([train_df, test_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# ✅ Manual 80-20 Split\n",
    "split_idx = int(len(merged_df) * 0.8)\n",
    "train_df = merged_df.iloc[:split_idx].reset_index(drop=True)\n",
    "valid_df = merged_df.iloc[split_idx:].reset_index(drop=True)\n",
    "\n",
    "# ✅ Function to Process and Save Images/Labels\n",
    "def process_and_save(df, img_dir, lbl_dir):\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        img_path, boxes, label = row[\"image\"], row[\"boxes\"], row[\"label\"]\n",
    "        image = cv2.imread(img_path)\n",
    "        h, w = image.shape[:2]\n",
    "        img_filename = os.path.basename(img_path)\n",
    "        cv2.imwrite(os.path.join(img_dir, img_filename), image)\n",
    "        lbl_path = os.path.join(lbl_dir, img_filename.replace(\".png\", \".txt\"))\n",
    "        if not boxes:\n",
    "            open(lbl_path, \"w\").close()\n",
    "            continue\n",
    "        yolo_boxes = [f\"{label} {(x1 + x2) / 2 / w:.6f} {(y1 + y2) / 2 / h:.6f} {(x2 - x1) / w:.6f} {(y2 - y1) / h:.6f}\" for x1, y1, x2, y2 in boxes]\n",
    "        with open(lbl_path, \"w\") as f:\n",
    "            f.write(\"\\n\".join(yolo_boxes))\n",
    "\n",
    "# ✅ Process and Save Data\n",
    "process_and_save(train_df, train_img_dir, train_lbl_dir)\n",
    "process_and_save(valid_df, valid_img_dir, valid_lbl_dir)\n",
    "\n",
    "# ✅ Create YOLO Dataset YAML File\n",
    "yolo_config = {\n",
    "    \"path\": DATASET_ROOT,\n",
    "    \"train\": \"train/images\",\n",
    "    \"val\": \"valid/images\",\n",
    "    \"names\": {0: \"mass\"}  # ✅ Single class for all masses\n",
    "}\n",
    "\n",
    "with open(os.path.join(DATASET_ROOT, \"cbis_ddsm.yaml\"), \"w\") as yaml_file:\n",
    "    yaml.dump(yolo_config, yaml_file)\n",
    "\n",
    "print(\"✅ YOLO dataset for CBIS-DDSM (Mass Detection) created successfully!\")\n",
    "\n",
    "# ✅ Train YOLO Model\n",
    "from ultralytics import YOLO\n",
    "\n",
    "data_yaml = os.path.join(DATASET_ROOT, \"cbis_ddsm.yaml\")\n",
    "model = YOLO(\"E:\\PFE\\Flower code\\yolo models\\yolo11m.pt\")\n",
    "model.train(\n",
    "    augment=True,\n",
    "    data=data_yaml,\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    optimizer=\"Adam\",  # Use Adam optimizer\n",
    "    lr0=0.0001,        # Learning rate\n",
    "    weight_decay=0.0005,\n",
    "    device=\"cuda\",\n",
    "    workers=4,\n",
    "    verbose=True\n",
    ")\n",
    "metrics = model.val(data=data_yaml, split=\"val\")\n",
    "\n",
    "print(\"Validation Results:\")\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
    "\n",
    "\n",
    "metrics = model.val(data=data_yaml, split=\"train\")\n",
    "\n",
    "print(\"training Results:\")\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3506127,
     "sourceId": 6117412,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6700933,
     "sourceId": 10796942,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6892532,
     "sourceId": 11061977,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6896427,
     "sourceId": 11067209,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6901562,
     "sourceId": 11074216,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
