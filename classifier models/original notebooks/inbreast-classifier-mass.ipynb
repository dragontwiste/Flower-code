{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label counts:/n",
      "label/n",
      "0    171/n",
      "1    168/n",
      "Name: count, dtype: int64/n",
      "/n",
      "Validation label counts:/n",
      "label/n",
      "0    45/n",
      "1    45/n",
      "Name: count, dtype: int64/n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c://Users//never//AppData//Local//Programs//Python//Python311//Lib//site-packages//torchvision//models//_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead./n",
      "  warnings.warn(/n",
      "c://Users//never//AppData//Local//Programs//Python//Python311//Lib//site-packages//torchvision//models//_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights./n",
      "  warnings.warn(msg)/n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training/n"
     ]
    }
   ],
   "source": [
    "import os/n",
    "import cv2/n",
    "import torch/n",
    "import pydicom/n",
    "import numpy as np/n",
    "import pandas as pd/n",
    "from PIL import Image/n",
    "from tqdm import tqdm/n",
    "from torchvision import models, transforms/n",
    "from torch.utils.data import Dataset, DataLoader/n",
    "import torch.nn as nn/n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix/n",
    "import matplotlib.pyplot as plt/n",
    "import seaborn as sns/n",
    "/n",
    "# ✅ Define paths (load directly from DICOM)/n",
    "ALLDICOMs = r/"E://PFE//Flower code//data original//INbreast Release 1.0//AllDICOMs/"/n",
    "XLS_PATH = r/"E://PFE//Flower code//data original//INbreast Release 1.0//INbreast.xls/"/n",
    "/n",
    "# ✅ Load metadata/n",
    "df = pd.read_excel(XLS_PATH)/n",
    "df.columns = df.columns.str.strip()/n",
    "df = df.dropna(subset=['File Name'])/n",
    "birads_followup = [/"4/", /"4a/", /"4b/", /"4c/", /"4d/", /"5/", /"6/", /"49/", /"2/"]/n",
    "df = df[(df['Bi-Rads'].astype(str).isin(birads_followup)) & (df[/"Mass/"] == /"X/")].reset_index(drop=True)/n",
    "/n",
    "# ✅ Add binary label/n",
    "def map_label(bi_rads):/n",
    "    return 0 if str(bi_rads).strip() == /"2/" else 1/n",
    "df['label'] = df['Bi-Rads'].apply(map_label)/n",
    "/n",
    "# ✅ Manual stratified split/n",
    "train_df = pd.DataFrame()/n",
    "valid_df = pd.DataFrame()/n",
    "for label in df['label'].unique():/n",
    "    group = df[df['label'] == label].sample(frac=1, random_state=42).reset_index(drop=True)/n",
    "    split_idx = int(len(group) * 0.8)/n",
    "    train_df = pd.concat([train_df, group.iloc[:split_idx]])/n",
    "    valid_df = pd.concat([valid_df, group.iloc[split_idx:]])/n",
    "/n",
    "train_df = train_df.reset_index(drop=True)/n",
    "valid_df = valid_df.reset_index(drop=True)/n",
    "/n",
    "# ✅ Multiply after stratified split/n",
    "train_df = pd.concat([/n",
    "    pd.concat([g]*9 if k == 0 else [g]*3)/n",
    "    for k, g in train_df.groupby('label')/n",
    "], ignore_index=True)/n",
    "/n",
    "valid_df = pd.concat([/n",
    "    pd.concat([g]*9 if k == 0 else [g]*3)/n",
    "    for k, g in valid_df.groupby('label')/n",
    "], ignore_index=True)/n",
    "/n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)/n",
    "valid_df = valid_df.sample(frac=1, random_state=42).reset_index(drop=True)/n",
    "/n",
    "# ✅ Print value counts/n",
    "print(/"Train label counts:/")/n",
    "print(train_df['label'].value_counts())/n",
    "print(/"//nValidation label counts:/")/n",
    "print(valid_df['label'].value_counts())/n",
    "/n",
    "# ✅ Dataset Class/n",
    "class InBreastBinaryDataset(Dataset):/n",
    "    def __init__(self, df, dicom_dir, transform=None):/n",
    "        self.df = df/n",
    "        self.dicom_dir = dicom_dir/n",
    "        self.transform = transform/n",
    "/n",
    "    def __len__(self):/n",
    "        return len(self.df)/n",
    "/n",
    "    def __getitem__(self, idx):/n",
    "        row = self.df.iloc[idx]/n",
    "        file_name = str(int(row['File Name']))/n",
    "        birads = str(row['Bi-Rads']).strip()/n",
    "        label = 0 if birads == /"2/" else 1/n",
    "/n",
    "        dicom_file = next((f for f in os.listdir(self.dicom_dir) if f.startswith(file_name)), None)/n",
    "        dcm_path = os.path.join(self.dicom_dir, dicom_file)/n",
    "        image = pydicom.dcmread(dcm_path).pixel_array.astype(np.float32)/n",
    "        image = (image - image.min()) / (image.max() - image.min())/n",
    "        image = (image * 255).astype(np.uint8)/n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))/n",
    "        image = clahe.apply(image)/n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)/n",
    "        image = Image.fromarray(image)/n",
    "/n",
    "        if self.transform:/n",
    "            image = self.transform(image)/n",
    "/n",
    "        return image, label/n",
    "/n",
    "# ✅ Data Augmentation for Training/n",
    "train_transform = transforms.Compose([/n",
    "    transforms.Resize((640, 640)),/n",
    "    transforms.RandomHorizontalFlip(p=0.5),/n",
    "    transforms.RandomRotation(degrees=90),/n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),/n",
    "    transforms.ToTensor(),/n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)/n",
    "])/n",
    "/n",
    "valid_transform = transforms.Compose([/n",
    "    transforms.Resize((640, 640)),/n",
    "    transforms.ToTensor(),/n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)/n",
    "])/n",
    "/n",
    "# ✅ Datasets and Loaders/n",
    "train_dataset = InBreastBinaryDataset(train_df, ALLDICOMs, transform=train_transform)/n",
    "valid_dataset = InBreastBinaryDataset(valid_df, ALLDICOMs, transform=valid_transform)/n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)/n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16)/n",
    "/n",
    "# ✅ Pretrained Model/n",
    "model = models.resnet50(pretrained=True)/n",
    "model.fc = nn.Linear(model.fc.in_features, 2)/n",
    "/n",
    "# ✅ Training Setup/n",
    "device = torch.device(/"cuda/" if torch.cuda.is_available() else /"cpu/")/n",
    "model.to(device)/n",
    "criterion = nn.CrossEntropyLoss()/n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)/n",
    "epochs = 54/n",
    "print(/"start training/")/n",
    "# ✅ Training Loop with Metrics/n",
    "for epoch in range(epochs):/n",
    "    model.train()/n",
    "    train_loss = 0/n",
    "    train_preds = []/n",
    "    train_labels = []/n",
    "/n",
    "    for images, labels in train_loader:/n",
    "        images, labels = images.to(device), labels.to(device)/n",
    "        preds = model(images)/n",
    "        loss = criterion(preds, labels)/n",
    "        optimizer.zero_grad()/n",
    "        loss.backward()/n",
    "        optimizer.step()/n",
    "/n",
    "        train_loss += loss.item()/n",
    "        train_preds.extend(preds.argmax(1).cpu().numpy())/n",
    "        train_labels.extend(labels.cpu().numpy())/n",
    "/n",
    "    train_acc = accuracy_score(train_labels, train_preds)/n",
    "    train_recall = recall_score(train_labels, train_preds)/n",
    "/n",
    "    model.eval()/n",
    "    valid_loss = 0/n",
    "    valid_preds = []/n",
    "    valid_labels = []/n",
    "    with torch.no_grad():/n",
    "        for images, labels in valid_loader:/n",
    "            images, labels = images.to(device), labels.to(device)/n",
    "            preds = model(images)/n",
    "            loss = criterion(preds, labels)/n",
    "/n",
    "            valid_loss += loss.item()/n",
    "            valid_preds.extend(preds.argmax(1).cpu().numpy())/n",
    "            valid_labels.extend(labels.cpu().numpy())/n",
    "/n",
    "    valid_acc = accuracy_score(valid_labels, valid_preds)/n",
    "    valid_recall = recall_score(valid_labels, valid_preds)/n",
    "/n",
    "    print(f/"Epoch {epoch+1} | Train Loss: {train_loss/len(train_loader):.4f} | Valid Loss: {valid_loss/len(valid_loader):.4f} | ///n",
    "          Train Acc: {train_acc:.4f} | Valid Acc: {valid_acc:.4f} | Train Recall: {train_recall:.4f} | Valid Recall: {valid_recall:.4f}/")/n",
    "/n",
    "# ✅ Save model/n",
    "torch.save(model.state_dict(), /"inbreast_binary_classifier.pth/")/n",
    "/n",
    "# ✅ Plot confusion matrix/n",
    "cm = confusion_matrix(valid_labels, valid_preds)/n",
    "plt.figure(figsize=(6, 5))/n",
    "sns.heatmap(cm, annot=True, fmt=/"d/", cmap=/"Blues/", xticklabels=[/"Benign/", /"Malignant/"], yticklabels=[/"Benign/", /"Malignant/"])/n",
    "plt.xlabel(/"Predicted/")/n",
    "plt.ylabel(/"Actual/")/n",
    "plt.title(/"Confusion Matrix/")/n",
    "plt.show()/n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2531491,
     "sourceId": 4296136,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
