{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-04T13:44:18.634038Z",
     "iopub.status.busy": "2025-04-04T13:44:18.633728Z",
     "iopub.status.idle": "2025-04-04T14:00:49.694480Z",
     "shell.execute_reply": "2025-04-04T14:00:49.693116Z",
     "shell.execute_reply.started": "2025-04-04T13:44:18.634013Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\never\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\never\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ✅ Dataset Paths\n",
    "TRAIN_PATH = r\"E:\\PFE\\Flower code\\data original\\DATA\\Mass\\Train\"\n",
    "TEST_PATH = r\"E:\\PFE\\Flower code\\data original\\DATA\\Mass\\Test\"\n",
    "\n",
    "# ✅ Collect image paths and labels\n",
    "def collect_data(root_path):\n",
    "    data = []\n",
    "    for label_name, label_id in [(\"BENIGN\", 0), (\"MALIGNANT\", 1)]:\n",
    "        class_path = os.path.join(root_path, label_name)\n",
    "        files = sorted(os.listdir(class_path))\n",
    "        for i in range(0, len(files), 2):  # alternate: image, mask\n",
    "            img_file = files[i]\n",
    "            if \"MASK\" in img_file:\n",
    "                continue\n",
    "            data.append([os.path.join(class_path, img_file), label_id])\n",
    "    return pd.DataFrame(data, columns=[\"image\", \"label\"])\n",
    "\n",
    "train_df = collect_data(TRAIN_PATH)\n",
    "test_df = collect_data(TEST_PATH)\n",
    "\n",
    "# ✅ Merge and Stratified Manual Split\n",
    "df = pd.concat([train_df, test_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_df, valid_df = pd.DataFrame(), pd.DataFrame()\n",
    "for label in df['label'].unique():\n",
    "    class_df = df[df['label'] == label]\n",
    "    split = int(0.8 * len(class_df))\n",
    "    train_df = pd.concat([train_df, class_df.iloc[:split]])\n",
    "    valid_df = pd.concat([valid_df, class_df.iloc[split:]])\n",
    "train_df, valid_df = train_df.reset_index(drop=True), valid_df.reset_index(drop=True)\n",
    "\n",
    "# ✅ Dataset Class\n",
    "class MassDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row[\"image\"]).convert(\"RGB\")\n",
    "        label = row[\"label\"]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# ✅ Transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=90),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# ✅ Loaders\n",
    "train_dataset = MassDataset(train_df, transform=train_transform)\n",
    "valid_dataset = MassDataset(valid_df, transform=valid_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16)\n",
    "\n",
    "# ✅ Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "model.to(device)\n",
    "\n",
    "# ✅ Training Setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "epochs = 95\n",
    "print(\"start training\")\n",
    "# ✅ Training Loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_preds, train_labels = [], []\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(preds.argmax(1).cpu().numpy())\n",
    "        train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(train_labels, train_preds)\n",
    "    train_recall = recall_score(train_labels, train_preds)\n",
    "\n",
    "    # ✅ Validation\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    valid_preds, valid_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            preds = model(images)\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            valid_preds.extend(preds.argmax(1).cpu().numpy())\n",
    "            valid_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    valid_acc = accuracy_score(valid_labels, valid_preds)\n",
    "    valid_recall = recall_score(valid_labels, valid_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss/len(train_loader):.4f} | Valid Loss: {valid_loss/len(valid_loader):.4f} | \"\n",
    "          f\"Train Acc: {train_acc:.4f} | Valid Acc: {valid_acc:.4f} | Train Recall: {train_recall:.4f} | Valid Recall: {valid_recall:.4f}\")\n",
    "\n",
    "# ✅ Save model\n",
    "torch.save(model.state_dict(), \"cbis_ddsm_resnet_classifier.pth\")\n",
    "\n",
    "# ✅ Confusion Matrix\n",
    "cm = confusion_matrix(valid_labels, valid_preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Benign\", \"Malignant\"], yticklabels=[\"Benign\", \"Malignant\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3506127,
     "sourceId": 6117412,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
